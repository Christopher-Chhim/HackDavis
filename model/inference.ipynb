{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "594e1f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\aurel\\miniconda3\\envs\\sentinelai\\Lib\\site-packages\\google\\~upb'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\aurel\\\\miniconda3\\\\envs\\\\sentinelai\\\\Lib\\\\site-packages\\\\matplotlib\\\\_c_internal_utils.cp310-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow==2.11.* tensorflow_io==0.28.* tensorflow-hub librosa soundfile numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764bb9f6",
   "metadata": {},
   "source": [
    "## Inference Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "283a21e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n",
      "Librosa Version: 0.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import soundfile as sf # Often used by librosa under the hood, good to have\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Librosa Version: {librosa.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc5acfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Cell 2: Audio Loading Function\n",
    "#\n",
    "# Define the function to load and preprocess audio files consistently with the training process.\n",
    "\n",
    "# %%\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\"\n",
    "    Loads a WAV file specified by the filename, converts it to 16kHz sample rate,\n",
    "    ensures it's mono channel, and returns the audio data as a float32 NumPy array.\n",
    "\n",
    "    Args:\n",
    "        filename (str or tf.Tensor): Path to the WAV file or a tf.Tensor containing the path.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A float32 NumPy array containing the audio waveform,\n",
    "                    or None if an error occurs during loading.\n",
    "    \"\"\"\n",
    "    # If filename is a tf.Tensor, convert it to a string path\n",
    "    if isinstance(filename, tf.Tensor):\n",
    "        path = filename.numpy().decode('utf-8')\n",
    "    else:\n",
    "        path = filename # Assume it's already a string path\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: Audio file not found at {path}\")\n",
    "        return None\n",
    "\n",
    "    # Load using librosa, ensure 16kHz sample rate and mono channel\n",
    "    try:\n",
    "        # use soundfile=False if you encounter issues, but default is often fine\n",
    "        wav, sample_rate = librosa.load(path, sr=16000, mono=True)\n",
    "        # Ensure float32 dtype, which is expected by YAMNet/TF models\n",
    "        return wav.astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing file {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Quick test of the function (optional)\n",
    "# Create a dummy wav file for testing if needed\n",
    "# sample_rate = 44100; duration = 1; freq = 440\n",
    "# t = np.linspace(0., duration, int(sample_rate * duration))\n",
    "# amplitude = np.iinfo(np.int16).max * 0.5\n",
    "# data = (amplitude * np.sin(2. * np.pi * freq * t)).astype(np.int16)\n",
    "# sf.write('dummy_audio.wav', data, sample_rate)\n",
    "# test_load = load_wav_16k_mono('dummy_audio.wav')\n",
    "# if test_load is not None:\n",
    "#    print(f\"Dummy audio loaded successfully, shape: {test_load.shape}, dtype: {test_load.dtype}\")\n",
    "#    os.remove('dummy_audio.wav') # Clean up dummy file\n",
    "# else:\n",
    "#    print(\"Dummy audio loading failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e39e9b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YAMNet model from TensorFlow Hub...\n",
      "YAMNet model loaded successfully.\n",
      "\n",
      "Loading custom scream detector model from: human_scream_detector (using TFSMLayer for Keras 3)\n",
      "Custom scream detector model loaded successfully via TFSMLayer and wrapped.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Cell 3: Load Pre-trained Models (Keras 3 Compatible)\n",
    "#\n",
    "# Load the YAMNet model from TensorFlow Hub and your custom-trained scream detector model saved in TensorFlow SavedModel format.\n",
    "# This version uses `TFSMLayer` for compatibility with Keras 3 loading SavedModel directories.\n",
    "#\n",
    "# **Important:** This cell assumes your trained model is saved in a directory named `human_scream_detector` in the same environment where you are running this notebook.\n",
    "\n",
    "# %%\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "\n",
    "# Define model paths/handles\n",
    "yamnet_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "saved_model_path = 'human_scream_detector' # <-- Make sure this path is correct!\n",
    "\n",
    "yamnet_model_inf = None\n",
    "scream_detector_model = None\n",
    "\n",
    "# Load YAMNet model\n",
    "print(\"Loading YAMNet model from TensorFlow Hub...\")\n",
    "try:\n",
    "    yamnet_model_inf = hub.load(yamnet_handle)\n",
    "    print(\"YAMNet model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YAMNet model: {e}\")\n",
    "    # yamnet_model_inf remains None\n",
    "\n",
    "# Load your custom scream detector model using TFSMLayer\n",
    "print(f\"\\nLoading custom scream detector model from: {saved_model_path} (using TFSMLayer for Keras 3)\")\n",
    "if os.path.exists(saved_model_path):\n",
    "    try:\n",
    "        # Load the inference function from the SavedModel as a Keras Layer\n",
    "        # 'serving_default' is the typical endpoint for models saved from Keras\n",
    "        scream_detector_layer = tf.keras.layers.TFSMLayer(saved_model_path, call_endpoint='serving_default')\n",
    "\n",
    "        # To make it easily usable with `.predict()`, wrap it in a Sequential model.\n",
    "        # We need to explicitly define the input shape expected by the original model.\n",
    "        # Your original model's input layer was Input(shape=(1024,), name='yamnet_embedding')\n",
    "        scream_detector_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(1024,), dtype=tf.float32, name='yamnet_embedding_input'), # Explicit Input layer\n",
    "            scream_detector_layer\n",
    "        ])\n",
    "\n",
    "        print(\"Custom scream detector model loaded successfully via TFSMLayer and wrapped.\")\n",
    "        # Optional: Display model architecture\n",
    "        # scream_detector_model.summary()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading custom model from {saved_model_path} using TFSMLayer: {e}\")\n",
    "        # scream_detector_model remains None\n",
    "else:\n",
    "    print(f\"ERROR: Saved model directory not found at '{saved_model_path}'.\")\n",
    "    print(\"Please ensure the path is correct and the model was saved previously.\")\n",
    "    # scream_detector_model remains None\n",
    "\n",
    "# Verify models are loaded before proceeding\n",
    "if yamnet_model_inf is None:\n",
    "    print(\"\\nWARNING: YAMNet model failed to load.\")\n",
    "if scream_detector_model is None:\n",
    "    print(\"\\nWARNING: Custom scream detector model failed to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39e89370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference function 'predict_scream' defined.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Cell 4: Define the Inference Function\n",
    "#\n",
    "# This function takes a path to a WAV file and uses the loaded models to predict whether it contains a scream.\n",
    "\n",
    "# %%\n",
    "def predict_scream(wav_file_path, yamnet_model, classifier_model, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Analyzes a WAV file to predict if it contains a human scream.\n",
    "\n",
    "    Args:\n",
    "        wav_file_path (str): The full path to the input WAV audio file.\n",
    "        yamnet_model: The loaded YAMNet model instance from TensorFlow Hub.\n",
    "        classifier_model: Your loaded custom Keras classifier model.\n",
    "        threshold (float): The probability threshold to classify as 'Scream'.\n",
    "                           Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "               - str: The prediction label ('Scream', 'Non-Scream', or 'Error').\n",
    "               - float: The predicted probability of the audio being a scream (0.0 to 1.0).\n",
    "                 Returns 0.0 if an error occurred before prediction.\n",
    "               Returns (None, None) if models are not loaded.\n",
    "    \"\"\"\n",
    "    # Pre-requisite checks\n",
    "    if yamnet_model is None or classifier_model is None:\n",
    "        print(\"Error: One or both models are not loaded. Cannot perform prediction.\")\n",
    "        return \"Error: Model not loaded\", 0.0\n",
    "\n",
    "    # 1. Load and preprocess audio\n",
    "    waveform_np = load_wav_16k_mono(wav_file_path)\n",
    "\n",
    "    if waveform_np is None: # Check if loading failed in the helper function\n",
    "        return \"Error: Audio Load Failed\", 0.0\n",
    "    if waveform_np.size == 0: # Check for empty audio data after loading\n",
    "        print(f\"Warning: Audio file {wav_file_path} resulted in empty data.\")\n",
    "        return \"Error: Empty Audio Data\", 0.0\n",
    "\n",
    "    # Convert NumPy array to TensorFlow tensor\n",
    "    waveform = tf.constant(waveform_np, dtype=tf.float32)\n",
    "\n",
    "    # 2. Extract YAMNet embeddings\n",
    "    try:\n",
    "        # YAMNet returns scores, embeddings, and log_mel_spectrogram\n",
    "        _, embeddings, _ = yamnet_model(waveform)\n",
    "        # embeddings shape is (N, 1024), where N is the number of frames\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting YAMNet embeddings for {wav_file_path}: {e}\")\n",
    "        return \"Error: YAMNet Failed\", 0.0\n",
    "\n",
    "    if tf.size(embeddings) == 0:\n",
    "         print(f\"Warning: YAMNet produced empty embeddings for {wav_file_path}. Might be too short?\")\n",
    "         # Handle very short files - predict non-scream? Or return error?\n",
    "         # Let's return non-scream with 0 probability for this case.\n",
    "         return \"Non-Scream\", 0.0 # Or potentially \"Error: Short Audio\"\n",
    "\n",
    "    # 3. Aggregate embeddings (calculate clip-level embedding)\n",
    "    #    Using reduce_mean, consistent with the training preprocessing\n",
    "    clip_embedding = tf.reduce_mean(embeddings, axis=0) # Shape -> (1024,)\n",
    "\n",
    "    # 4. Prepare for classifier (add batch dimension)\n",
    "    model_input = tf.expand_dims(clip_embedding, axis=0) # Shape -> (1, 1024)\n",
    "\n",
    "    # 5. Make prediction using the custom classifier\n",
    "    try:\n",
    "        probability = classifier_model.predict(model_input, verbose=0)[0, 0] # Get scalar prob\n",
    "    except Exception as e:\n",
    "        print(f\"Error during classifier prediction for {wav_file_path}: {e}\")\n",
    "        return \"Error: Classifier Failed\", 0.0\n",
    "\n",
    "    # 6. Determine label based on the threshold\n",
    "    prediction_label = \"Scream\" if probability >= threshold else \"Non-Scream\"\n",
    "\n",
    "    return prediction_label, float(probability)\n",
    "\n",
    "print(\"Inference function 'predict_scream' defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a53c186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference function 'predict_scream' (with debugging) defined.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Cell 4: Define the Inference Function (with Debugging)\n",
    "#\n",
    "# This function takes a path to a WAV file and uses the loaded models to predict whether it contains a scream. Includes extra print statements for debugging.\n",
    "\n",
    "# %%\n",
    "import tensorflow as tf # Ensure TF is imported if running this cell independently\n",
    "import numpy as np # Ensure numpy is imported\n",
    "import os # Ensure os is imported\n",
    "\n",
    "def predict_scream(wav_file_path, yamnet_model, classifier_model, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Analyzes a WAV file to predict if it contains a human scream.\n",
    "    Includes enhanced debugging prints.\n",
    "\n",
    "    Args:\n",
    "        wav_file_path (str): The full path to the input WAV audio file.\n",
    "        yamnet_model: The loaded YAMNet model instance from TensorFlow Hub.\n",
    "        classifier_model: Your loaded custom Keras classifier model (wrapped TFSMLayer).\n",
    "        threshold (float): The probability threshold to classify as 'Scream'. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "               - str: The prediction label ('Scream', 'Non-Scream', or 'Error:...').\n",
    "               - float: The predicted probability (0.0 to 1.0).\n",
    "    \"\"\"\n",
    "    print(f\"--- Debug: Starting prediction for {wav_file_path} ---\")\n",
    "\n",
    "    # Pre-requisite checks\n",
    "    if yamnet_model is None or classifier_model is None:\n",
    "        print(\"Debug: Error - One or both models are not loaded.\")\n",
    "        return \"Error: Model not loaded\", 0.0\n",
    "\n",
    "    # 1. Load and preprocess audio\n",
    "    print(f\"Debug: Loading audio...\")\n",
    "    waveform_np = load_wav_16k_mono(wav_file_path) # Assumes load_wav_16k_mono is defined (Cell 2)\n",
    "\n",
    "    if waveform_np is None:\n",
    "        print(\"Debug: Error - Audio loading returned None.\")\n",
    "        return \"Error: Audio Load Failed\", 0.0\n",
    "    if waveform_np.size == 0:\n",
    "        print(\"Debug: Error - Audio data is empty after loading.\")\n",
    "        return \"Error: Empty Audio Data\", 0.0\n",
    "    print(f\"Debug: Audio loaded, shape: {waveform_np.shape}, dtype: {waveform_np.dtype}\")\n",
    "\n",
    "    # Convert NumPy array to TensorFlow tensor\n",
    "    waveform = tf.constant(waveform_np, dtype=tf.float32)\n",
    "\n",
    "    # 2. Extract YAMNet embeddings\n",
    "    print(f\"Debug: Extracting YAMNet embeddings...\")\n",
    "    try:\n",
    "        scores, embeddings, spectrogram = yamnet_model(waveform)\n",
    "        print(f\"Debug: YAMNet embeddings extracted, shape: {embeddings.shape}\")\n",
    "        # Check for NaNs/Infs in embeddings\n",
    "        if tf.reduce_any(tf.math.is_nan(embeddings)) or tf.reduce_any(tf.math.is_inf(embeddings)):\n",
    "            print(\"Debug: WARNING - NaNs or Infs found in raw YAMNet embeddings!\")\n",
    "            # Optional: return error or try to proceed? Let's try proceeding for now.\n",
    "    except Exception as e:\n",
    "        print(f\"Debug: Error during YAMNet embedding extraction: {e}\")\n",
    "        return \"Error: YAMNet Failed\", 0.0\n",
    "\n",
    "    if tf.size(embeddings) == 0:\n",
    "         print(f\"Debug: Error - YAMNet produced empty embeddings. Audio might be too short.\")\n",
    "         return \"Error: Empty Embeddings\", 0.0\n",
    "\n",
    "    # 3. Aggregate embeddings\n",
    "    print(f\"Debug: Aggregating embeddings...\")\n",
    "    clip_embedding = tf.reduce_mean(embeddings, axis=0)\n",
    "    print(f\"Debug: Clip embedding calculated, shape: {clip_embedding.shape}\")\n",
    "    if tf.reduce_any(tf.math.is_nan(clip_embedding)) or tf.reduce_any(tf.math.is_inf(clip_embedding)):\n",
    "        print(\"Debug: WARNING - NaNs or Infs found in aggregated clip embedding!\")\n",
    "        # Decide how to handle this, maybe return an error?\n",
    "        # return \"Error: Invalid Embedding\", 0.0\n",
    "\n",
    "    # 4. Prepare for classifier (add batch dimension)\n",
    "    model_input = tf.expand_dims(clip_embedding, axis=0)\n",
    "    print(f\"Debug: Prepared model input, shape: {model_input.shape}, dtype: {model_input.dtype}\")\n",
    "\n",
    "    # 5. Make prediction using the custom classifier\n",
    "    print(f\"Debug: Making prediction with classifier...\")\n",
    "    try:\n",
    "        # --- IMPORTANT DEBUG STEP ---\n",
    "        # Call predict and inspect the raw output *before* indexing\n",
    "        raw_output = classifier_model.predict(model_input, verbose=0)\n",
    "        print(f\"    Debug: Raw classifier output: {raw_output}\")\n",
    "        print(f\"    Debug: Type of raw output: {type(raw_output)}\")\n",
    "        if hasattr(raw_output, 'shape'):\n",
    "            print(f\"    Debug: Shape of raw output: {raw_output.shape}\")\n",
    "        # --- End Debug Step ---\n",
    "\n",
    "        # Now, try to extract the probability, adjusting indexing if needed based on debug output\n",
    "        # Original attempt:\n",
    "        probability = raw_output['dense_2'][0, 0]\n",
    "        # If raw_output shape is (1,), use:\n",
    "        # probability = raw_output[0]\n",
    "        # If raw_output is a dict, access the correct key:\n",
    "        # probability = raw_output['output_key_name'][0, 0] # Replace 'output_key_name'\n",
    "\n",
    "        print(f\"Debug: Probability extracted: {probability}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Debug: Error during classifier prediction or result extraction !!!\")\n",
    "        print(f\"    Exception Type: {type(e)}\")\n",
    "        print(f\"    Exception Args: {e.args}\")\n",
    "        print(f\"    Full Exception: {e}\")\n",
    "        # Also print the input shape just before prediction attempt\n",
    "        print(f\"    Input shape to classifier was: {model_input.shape}\")\n",
    "        return \"Error: Classifier Failed\", 0.0\n",
    "\n",
    "    # 6. Determine label based on the threshold\n",
    "    prediction_label = \"Scream\" if probability >= threshold else \"Non-Scream\"\n",
    "    print(f\"Debug: Final Label: {prediction_label}, Probability: {float(probability)}\")\n",
    "    print(f\"--- Debug: Prediction finished for {wav_file_path} ---\")\n",
    "\n",
    "    return prediction_label, float(probability)\n",
    "\n",
    "print(\"Inference function 'predict_scream' (with debugging) defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01be324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Debug: Starting prediction for screaming.wav ---\n",
      "Debug: Loading audio...\n",
      "Debug: Audio loaded, shape: (160000,), dtype: float32\n",
      "Debug: Extracting YAMNet embeddings...\n",
      "Debug: YAMNet embeddings extracted, shape: (20, 1024)\n",
      "Debug: Aggregating embeddings...\n",
      "Debug: Clip embedding calculated, shape: (1024,)\n",
      "Debug: Prepared model input, shape: (1, 1024), dtype: <dtype: 'float32'>\n",
      "Debug: Making prediction with classifier...\n",
      "    Debug: Raw classifier output: {'dense_2': array([[0.7935498]], dtype=float32)}\n",
      "    Debug: Type of raw output: <class 'dict'>\n",
      "Debug: Probability extracted: 0.7935497760772705\n",
      "Debug: Final Label: Scream, Probability: 0.7935497760772705\n",
      "--- Debug: Prediction finished for screaming.wav ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Scream', 0.7935497760772705)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_scream('screaming.wav', yamnet_model_inf, scream_detector_model, threshold=0.5) # Example call to test the function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentinelai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
